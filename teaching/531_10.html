<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
	<meta charset="utf-8"/>
	<title>Phonetics {and, v., or} phonology</title>
	<meta name="author" content="Brian W. Smith"/>
	<meta name="date" content="10/12/2019"/>
	<link type="text/css" rel="stylesheet" href="bws.css"/>
</head>
<body>

<!-- Standard header. Change title in metadata -->

<p><a href="531_guide.html">USC Graduate Phonology</a> ✳︎ Fall 2019 ✳︎ Smith</p>

<hr />

<div class="title">

<p>Phonetics {and, v., or} phonology</p>

</div>

<div class="TOC">

<ul>
<li><a href="#recall:justifyingconstraints">Recall: justifying constraints</a></li>
<li><a href="#phoneticsvs.phonology">Phonetics vs. phonology</a></li>
<li><a href="#definitelyphonologicalrulesatleastprobably">Definitely phonological rules (at least probably)</a></li>
<li><a href="#crazyrules">Crazy rules</a></li>
<li><a href="#phoneticandphonologicaldoublets">Phonetic and phonological &#8220;doublets&#8221;</a></li>
<li><a href="#revisitingthestrictdividebetweenphonologyandphonetics">Revisiting the strict divide between phonology and phonetics</a></li>
<li><a href="#hayes1999:learningphonologicalconstraintsusingphonetics">Hayes (1999): learning phonological constraints using phonetics</a></li>
<li><a href="#steriade2001:faithfulnessconstraintsdrivenbyperception">Steriade (2001): faithfulness constraints driven by perception</a></li>
<li><a href="#somethingstoponderaboutthep-map">Some things to ponder about the P-map</a></li>
<li><a href="#the“too-many-solutions”problemrevisited">The “too-many-solutions” problem revisited</a></li>
<li><a href="#recap">Recap</a></li>
</ul>
</div>

<hr />

<h1 id="recall:justifyingconstraints">Recall: justifying constraints</h1>

<ul>
<li>There are three ways to justify a constraint:

<ul>
<li><strong>Formal</strong>: resembles other constraints in CON.</li>
<li><strong>Functional</strong>: reflects articulation, perception, or memory.

<ul>
<li>Examples: Agree, Ident-Onset[Voice]</li>
<li>Potentially includes audience design</li>
</ul></li>
<li><strong>Typological</strong>: its cross-linguistic typological predictions are borne out.</li>
</ul></li>
<li>Today we&#8217;ll tackle functional justification.</li>
</ul>

<h1 id="phoneticsvs.phonology">Phonetics vs. phonology</h1>

<ul>
<li>Widespread assumptions about the generative grammar (see e.g. Steriade 1997, who argues against this model, and Hayes 1999 who assumes it)

<ul>
<li>There is a phonological component of the model

<ul>
<li>Determines which sounds contrast and where</li>
<li>Manipulates phonological representations</li>
</ul></li>
<li>There is a phonetic component of the model

<ul>
<li>Maps phonological representations onto articulatory instructions</li>
</ul></li>
<li>These two models are separate, but the phonological model feeds the phonetic model.

<ul>
<li>The interaction is &#8220;one-way&#8221; (feedforward with no feedback) &#8211; phonology doesn&#8217;t consider physical factors directly, although phonological processes are possibly shaped (over time?) by functional considerations and phonetic &#8220;naturalness.&#8221;</li>
</ul></li>
</ul></li>
</ul>

<h1 id="definitelyphonologicalrulesatleastprobably">Definitely phonological rules (at least probably)</h1>

<ul>
<li>There are some processes that seem unambiguously phonological (see Kenstowicz &amp; Kissberth 1978, Ch 2: The Nonphonetic Basis of Phonology for examples).

<ul>
<li>They refer to grammatical or lexical information.

<ul>
<li>For example, they refer to syntactic categories.</li>
<li>For example, they are sensitive to morpheme boundaries.</li>
<li>For example, they have morphological or lexical exceptions.</li>
</ul></li>
<li>They aren&#8217;t phonetically natural, usually due to historical change.

<ul>
<li>Telescoping: multiple sound changes &#8211; each of which is natural &#8211; results in an phonetically unmotivated synchronic alternation.</li>
<li>Inversion: e.g., a phonetically natural rule of deletion is reanalyzed as a rule of epenthesis.</li>
<li>Paradigm leveling and analogy</li>
</ul></li>
<li>These assume phonetic rules don&#8217;t refer to boundaries or lexical information, which now seems wrong, at least with respect to prosodic boundaries and item-specific phonetics.</li>
</ul></li>
</ul>

<h1 id="crazyrules">Crazy rules</h1>

<ul>
<li>Bach &amp; Harms (1972) <em>How do languages get crazy rules?</em> addresses how this might happen.

<ul>
<li>This is a great paper to know and is a real classic.</li>
</ul></li>
<li>One of their examples is Japanese palatalization.

<ul>
<li>Here is the pattern:</br>/t/ ta tʃi tsu </br> /s/ sa ʃi su </br> /d/ da dʒi (zu) </br> /z/ za (dʒi) zu</li>
</ul></li>
</ul>

<figure>
<img src="J.png" alt="A crazy rule" />
<figcaption>A crazy rule</figcaption>
</figure>

<ul>
<li>Bach &amp; Harms say: &#8220;Under any feature system we can think of the rule exhibits interconnections that do not seem have any particular phonetic or phonological plausibility&#8221; <a href="#fn:1" id="fnref:1" title="see footnote" class="footnote"><sup>1</sup></a>

<ul>
<li>Affrication before [u] seems especially unnatural.</li>
</ul></li>
<li>They suggest that this &#8220;crazy rule&#8221; arose via a series of simplifications and combinations of more plausible rules (see <em>telescoping</em> above).</li>
<li>For each step, let&#8217;s write out the inventory.</li>
</ul>

<figure>
<img src="J1.png" alt="Step 1 (this is a "quite plausible" rule)" />
<figcaption>Step 1 (this is a &#8220;quite plausible&#8221; rule)</figcaption>
</figure>

<figure>
<img src="J2.png" alt="Step 2 (This apparently corresponds to actual 17th century Japanese)" />
<figcaption>Step 2 (This apparently corresponds to actual 17th century Japanese)</figcaption>
</figure>

<figure>
<img src="J3.png" alt="Step 3 (a new rule in addition to J2)" />
<figcaption>Step 3 (a new rule in addition to J2)</figcaption>
</figure>

<figure>
<img src="J4.png" alt="Step 4 (generalized from J4)" />
<figcaption>Step 4 (generalized from J4)</figcaption>
</figure>

<figure>
<img src="J.png" alt="Step 5 ("they must all be collapsed into the unholy rule J")" />
<figcaption>Step 5 (&#8220;they must all be collapsed into the unholy rule J&#8221;)</figcaption>
</figure>

<ul>
<li>Why not three rules?

<ul>
<li>Palatalization, affrication, neutralization of voiced strIdents</li>
<li>All three processes target the same class of obstruents</li>
<li>The three processes aren&#8217;t inDependent: no dialect has affrication by itself.</li>
<li>The three rules would never be reordered with respect to another, and no rule ever comes between. (They act as a unit in terms of rule ordering.)</li>
</ul></li>
<li>Because of processes like these, the dream of a strictly innate universal constraint set probably won&#8217;t be fulfilled. For crazy processes, we probably need a way for learners to posit crazy constraints.</li>
</ul>

<h1 id="phoneticandphonologicaldoublets">Phonetic and phonological &#8220;doublets&#8221;</h1>

<ul>
<li>We&#8217;ve discussed what phonological processes can look like, now let&#8217;s return to phonetics.</li>
<li>Both components &#8211; phonetic and phonological &#8211; can generate very similar looking processes.

<ul>
<li>Sometimes a phonetic process becomes <strong>phonologized</strong>, wherein the phonetic process becomes a phonological process.</li>
<li>Here are some examples from Hyman (2013) of processes that can either be phonetic or phonological, Depending on the language.</li>
<li>If the triggering environment disappears due to a sound change, the phonetic conditioning is lost, and the process is unambigously phonological (maybe even resulting in contrast).</li>
</ul></li>
</ul>

<table>
<caption style="caption-side: bottom;" id="phonologicalandphoneticdoubletsfromhyman2013">Phonological and phonetic &#8220;doublets&#8221; from Hyman (2013)</caption>
<colgroup>
<col />
<col />
<col />
</colgroup>

<thead>
<tr>
	<th>process </th>
	<th>  subsequent developments </th>
	<th> (incl. loss of trigger)</th>
</tr>
</thead>

<tbody>
<tr>
	<td>lengthening before voiced Cs: </td>
	<td> /ab/ → [a:b] </td>
	<td> (&gt; a:p)</td>
</tr>
<tr>
	<td>palatalization: </td>
	<td> /ki/ → [k<sup>j</sup> i] </td>
	<td>(&gt; či, ši, tsi, si)</td>
</tr>
<tr>
	<td>high vowel frication: </td>
	<td> /ku/ → [k<sup>h</sup> u] </td>
	<td>(&gt; k<sup>x</sup> u, k<sup>f</sup> u, p<sup>f</sup> u, fu)</td>
</tr>
<tr>
	<td>anticipatory nasalization: </td>
	<td> /an/ → [ãn] </td>
	<td> (&gt; ã<sup>N</sup>, ã:, ã)</td>
</tr>
<tr>
	<td>umlaut, metaphony: </td>
	<td> /aCi/ → [æCi] </td>
	<td>(&gt; εCi, εCә, εC)</td>
</tr>
<tr>
	<td>tonogenesis from coda: </td>
	<td> /aʔ/ → [áʔ] </td>
	<td> (&gt; á) </td>
</tr>
<tr>
	<td>tonogenesis from phonation: </td>
	<td> /a̰ʔ/ → [à̰ʔ] </td>
	<td> (&gt; à) </td>
</tr>
<tr>
	<td>tonal bifurcation from onset: </td>
	<td> /bá/ → [bǎ] </td>
	<td> (&gt; pǎ) </td>
</tr>
</tbody>
</table>

<ul>
<li>How do we determine what&#8217;s phonetic and what&#8217;s phonological if it&#8217;s like one of the processes above?

<ul>
<li>This isn&#8217;t as easy as you might think…</li>
<li>Here are some characteristic differences from Hyman (2013), who cites: Cohn 1998, 2007; Keating 1996; Keyser and Stevens 2001; Kingston 2007; Pierrehumbert 1990; Stevens and Keyser 1989, etc.</li>
<li>Both phonology and phonetics seem to be language-specific to some degree.</li>
<li>Both phonology and phonetics seem to be subject to optionality to some degree.</li>
</ul></li>
</ul>

<table>
<caption style="caption-side: bottom;" id="phoneticsvs.phonologyinhyman2013">Phonetics vs. phonology in Hyman (2013)</caption>
<colgroup>
<col />
<col />
</colgroup>

<thead>
<tr>
	<th> phonetics </th>
	<th> phonology </th>
</tr>
</thead>

<tbody>
<tr>
	<td>gradient </td>
	<td> categorical</td>
</tr>
<tr>
	<td>continuous </td>
	<td> discrete</td>
</tr>
<tr>
	<td>quantitative </td>
	<td> qualitative</td>
</tr>
<tr>
	<td>physical </td>
	<td> symbolic</td>
</tr>
<tr>
	<td>analog </td>
	<td> digital</td>
</tr>
</tbody>
</table>

<ul>
<li>Two traditional diagnostics from Hyman (2013). A process has been phonologized if…

<ul>
<li>A phonetic effect is exaggerated beyond what can be considered universal (e.g. duration increases more than we&#8217;d expect)</li>
<li>A ‘categorical’ rule of phonology refers to it. (e.g. a clearly phonological process refers to vowel length, than that length must be phonological)</li>
</ul></li>
</ul>

<h1 id="revisitingthestrictdividebetweenphonologyandphonetics">Revisiting the strict divide between phonology and phonetics</h1>

<ul>
<li>If we assume that phonology can come from phonetics, an open question is how to connect them.</li>
<li>Two papers today:

<ul>
<li>Hayes (1999): A feedforward model, except for the induction of phonological constraints. Learning (phonologized) constraints involves a tradeoff between increasing ease of articulation and minimizing complexity.</li>
<li>Steriade (2001): Complicated typological patterns in assimilation can be explained by appealing to ease of perception and confusability.

<ul>
<li>Both papers use maps of difficulty: one for articulation (Hayes) andd one for perception (Steriade).</li>
</ul></li>
</ul></li>
</ul>

<h1 id="hayes1999:learningphonologicalconstraintsusingphonetics">Hayes (1999): learning phonological constraints using phonetics</h1>

<ul>
<li>Questions for discussion:

<ul>
<li>What are the main goals of the paper?</li>
<li>What factors influence the ease of voicing in obstruents?

<ul>
<li>Let&#8217;s go over them and discuss how and why.</li>
<li>What about sonorants?</li>
</ul></li>
<li>Where does the map of articulatory difficulty come from?</li>
<li>How is the map used to induce constraints?</li>
<li>Under Hayes' model, to what extent is CON universal?</li>
<li>Does Hayes' model address the too-many-repairs problem?</li>
<li>What constraints (if any) have we talked about that couldn&#8217;t be induced under the algorithm presented here?</li>
</ul></li>
</ul>

<h1 id="steriade2001:faithfulnessconstraintsdrivenbyperception">Steriade (2001): faithfulness constraints driven by perception</h1>

<ul>
<li>Why do so many languages have /an+pa/ → [ampa] but not /an+pa/ → [anta], /ap+na/ → [apma]?

<ul>
<li>One possible answer à la Lombardi (1999): protect onsets</li>
<li>Steriade&#8217;s approach: in /an+pa/, /p/’s place is well cued (release burst, outgoing formant transition), while /n/’s isn’t.</li>
<li><strong>Be faithful to the better-cued contrast.</strong></li>
<li>Example of how different contexts for a stop have better and worse perceptual cues.</li>
</ul></li>
</ul>

<p><img src="ada.png" alt="Best: VCV" />
<img src="adba.png" alt="Worse: VC" />
<img src="aldba.png" alt="Worst: VCCCV" /></p>

<ul>
<li>Why this looks like a good idea: protecting onsets can&#8217;t account for how place and manner of articulation affects the directionality of assimilation.

<ul>
<li>The likelihood of a process being regressive Depends on what the two sounds are, in both place and manner.</li>
</ul></li>
</ul>

<figure>
<img src="steriade_manner.png" alt="Place effects" />
<figcaption>Place effects</figcaption>
</figure>

<figure>
<img src="steriade_place.png" alt="Manner effects" />
<figcaption>Manner effects</figcaption>
</figure>

<ul>
<li>Given the basic idea (preserve the better-cued constrast)

<ul>
<li>…speculate why apicals are progressive while non-apicals are regressive</li>
<li>…speculate why nasal+obstruent sequencess in apicals are regressive</li>
</ul></li>
<li>The implemented model: speakers have a “P-map”

<ul>
<li>implicit knowledge of perceptual distance ∆(X,Y) between any pair of sounds X, Y (potentially tagged for their contexts):</li>
</ul></li>
</ul>

<figure>
<img src="pmap.png" alt="The P-map" />
<figcaption>The P-map</figcaption>
</figure>

<ul>
<li>We&#8217;ll consider a simplified example, where ∆(p/__V, t/__V) &gt; ∆(n/__C, m/__C) (∆ for difference)</li>
<li>Faithfulness constraints can refer to details of their target and their surface context:

<ul>
<li>not just Ident(place) but Ident(place):[–son]/ __ V, Ident(place):[+nas]/ __ C</li>
<li>not just Dep-V, but Dep-i, Dep-a, Dep-ə, Dep-V/s__t, Dep-V/t__r, &#8230;</li>
</ul></li>
<li>Constraints penalizing big changes should outrank constraints penalizing small changes:

<ul>
<li>Ident(place): [–son] / __V &gt;&gt; Ident(place):[+nas] / __ C</li>
</ul></li>
<li>Presumably these default rankings can be overturned by the learner in response to contradictory data, but they will be a drag on language change</li>
</ul>

<table>
<colgroup>
<col />
<col />
<col />
<col />
</colgroup>

<thead>
<tr>
	<th>I→O </th>
	<th> faith. violated </th>
	<th> perceptual comparison </th>
	<th> distance (fake values)</th>
</tr>
</thead>

<tbody>
<tr>
	<td>/an+pa/ → [ampa] </td>
	<td> Ident(place): [+nas]/ __ C </td>
	<td> (nas/__C, diff-place-nas/__C) </td>
	<td> 6</td>
</tr>
<tr>
	<td>/an+pa/ → [anta] </td>
	<td> Ident(place): [–son]/ __ V </td>
	<td> (obstr/__V, diff-place-obstr/__V) </td>
	<td> 8</td>
</tr>
<tr>
	<td>/an+pa/ → [apa] </td>
	<td> Max-C/__C </td>
	<td> (C/__C, Ø/__C) </td>
	<td> 9</td>
</tr>
<tr>
	<td>/an+pa/ → [ana] </td>
	<td> Max-C/__V </td>
	<td> (C/__V, Ø/__V) </td>
	<td> 10</td>
</tr>
</tbody>
</table>

<ul>
<li>No matter where we rank the markedness constraint in relation to the faithfulness hierarchy, winner is (b) or (a):</li>
</ul>

<table>
<colgroup>
<col />
<col style="text-align:center;"/>
<col style="text-align:center;"/>
<col style="text-align:center;"/>
<col style="text-align:center;"/>
<col style="text-align:center;"/>
</colgroup>

<thead>
<tr>
	<th>/an+pa/ </th>
	<th style="text-align:center;"> Agree(place) </th>
	<th style="text-align:center;"> Max&#8211;C/__V </th>
	<th style="text-align:center;"> Max&#8211;C/__C </th>
	<th style="text-align:center;"> Ident(place): [–son]/ __ V </th>
	<th style="text-align:center;"> Ident(place): [+nas]/ __ C</th>
</tr>
</thead>

<tbody>
<tr>
	<td>a [anpa] </td>
	<td style="text-align:center;"> ✳︎! </td>
	<td style="text-align:center;"> </td>
	<td style="text-align:center;"> </td>
	<td style="text-align:center;"> </td>
	<td style="text-align:center;"> </td>
</tr>
<tr>
	<td>b [ampa] </td>
	<td style="text-align:center;"> </td>
	<td style="text-align:center;"> </td>
	<td style="text-align:center;"> </td>
	<td style="text-align:center;"> </td>
	<td style="text-align:center;"> ✳︎!</td>
</tr>
<tr>
	<td>c [anta] </td>
	<td style="text-align:center;"> </td>
	<td style="text-align:center;"> </td>
	<td style="text-align:center;"> </td>
	<td style="text-align:center;"> ✳︎! </td>
	<td style="text-align:center;"> </td>
</tr>
<tr>
	<td>d [ana]  </td>
	<td style="text-align:center;"> </td>
	<td style="text-align:center;"> ✳︎! </td>
	<td style="text-align:center;">  </td>
	<td style="text-align:center;"> </td>
	<td style="text-align:center;"> </td>
</tr>
<tr>
	<td>e [apa]  </td>
	<td style="text-align:center;"> </td>
	<td style="text-align:center;"> </td>
	<td style="text-align:center;"> ✳︎! </td>
	<td style="text-align:center;"> </td>
	<td style="text-align:center;"> </td>
</tr>
</tbody>
</table>

<h1 id="somethingstoponderaboutthep-map">Some things to ponder about the P-map</h1>

<ul>
<li>Exactly what is being compared in ∆(X,Y), to give a faithfulness constraint its default ranking?

<ul>
<li>Output vs. input? That’s kind of funny because the input isn’t a pronounced form, so its perceptual properties are hypothetical.</li>
<li>Output vs. faithful output (candidate a in the above)?</li>
<li>Output vs. related output? E.g., [rat] vs. [rad-im].

<ul>
<li>Those are both real, pronounced forms, but it’s tricky because the target segments are in different contexts.</li>
<li>Do we measure ∆(d/V__V, t/V__#)?</li>
</ul></li>
</ul></li>
<li>How well connected is the P-map?

<ul>
<li>Can ∆(X,Y) be measured for absolutely any X,Y? Or only for close-enough pairs?</li>
<li>Does ∆(X,Y) really act like a number, so that we can always compare ∆(X,Y) and ∆(Z,W)?</li>
<li>Or is the “greater than” relation sparser than that, so that some distances can’t be compared?</li>
</ul></li>
</ul>

<h1 id="the“too-many-solutions”problemrevisited">The “too-many-solutions” problem revisited</h1>

<ul>
<li>Some markedness constraints have a variety of “solutions”

<ul>
<li>*NC̥, as we saw</li>
<li>OCP-labial in various Western Austronesian languages (Zuraw &amp; Lu 2009)</li>
<li>*{ɪ,ʊ} in Romance metaphony (Walker 2005)</li>
<li>*InitialGeminate (Kennedy 2005)</li>
</ul></li>
<li>This is what we expect in OT

<ul>
<li>But some don’t — that’s the “too-many-solutions problem”:

<ul>
<li>*NC̥ never causes epenthesis</li>
<li>*CC deletes C<sub>1</sub>, not C<sub>2</sub> in VC<sub>1</sub> C<sub>2</sub> V (Wilson 2000; Wilson 2001)</li>
<li>*[–son, +voice]# causes final devoicing, but not deletion, epenthesis, etc.</li>
</ul></li>
<li>The lack of solutions for *[–son, +voice]# is predicted, if the P-map imposes a difficult-to-overturn ranking: Max-C, Dep-V &gt;&gt; Ident(voice)/__#

<ul>
<li>Deletion and epenthesis result in very perceptually salient differences, while devoicing doesn&#8217;t.</li>
</ul></li>
</ul></li>
</ul>

<h1 id="recap">Recap</h1>

<ul>
<li>Crazy rules</li>
<li>Phonetics v. phonology: tough calls</li>
<li>Universal CON: maybe not</li>
<li>Hayes: Induction of markedness based on articultion</li>
<li>Steriade: Perception-based faithfulness</li>
</ul>

<div class="footnotes">
<hr />
<ol>

<li id="fn:1">
<p>USC PhD candidate Hayeun Jang has a phonetic story for parts (but not all!) of the weirdness. See her recent talk at the ASA. <a href="#fnref:1" title="return to body" class="reversefootnote">&#160;&#8617;</a></p>
</li>

</ol>
</div>

</body>
</html>

