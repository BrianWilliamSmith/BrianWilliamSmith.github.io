Title: Phonetics {and, v., or} phonology
Author: Brian W. Smith
Date: 10/12/2019
CSS: bws.css

<!-- Standard header. Change title in metadata -->

[USC Graduate Phonology](531_guide.html) ✳︎ Fall 2019 ✳︎ Smith
***

<div class="title">

[%title]

</div>

{{TOC}}

***

# Recall: justifying constraints
-   There are three ways to justify a constraint:
    - **Formal**: resembles other constraints in CON.
    - **Functional**: reflects articulation, perception, or memory.
        + Examples: Agree, Ident-Onset[Voice]
        + Potentially includes audience design
    - **Typological**: its cross-linguistic typological predictions are borne out.
- Today we'll tackle functional justification.

# Phonetics vs. phonology
- Widespread assumptions about the generative grammar (see e.g. Steriade 1997, who argues against this model, and Hayes 1999 who assumes it)
    + There is a phonological component of the model
        * Determines which sounds contrast and where
        * Manipulates phonological representations
    + There is a phonetic component of the model
        * Maps phonological representations onto articulatory instructions
    + These two models are separate, but the phonological model feeds the phonetic model.
        * The interaction is "one-way" (feedforward with no feedback) -- phonology doesn't consider physical factors directly,  although phonological processes are possibly shaped (over time?) by functional considerations and phonetic "naturalness."
- There are some processes that seem unambiguously phonological (see Kenstowicz & Kissberth 1978, Ch 2: The Nonphonetic Basis of Phonology for examples).
    + They refer to grammatical or lexical information.
        + For example, they refer to syntactic categories.
        + For example, they are sensitive to morpheme boundaries.
        + For example, they have morphological or lexical exceptions.
    + They aren't phonetically natural, usually due to historical change.
        * Telescoping: multiple sound changes -- each of which is natural -- results in an phonetically unmotivated synchronic alternation.
        * Inversion: e.g., a phonetically natural rule of deletion is reanalyzed as a rule of epenthesis.
        * Paradigm leveling and analogy
    - These assume phonetic rules don't refer to boundaries or lexical information, which now seems wrong, at with respect to prosodic boundaries and item-specific phonetics.
- Both components -- phonetic and phonological -- can generate very similar looking processes.
    - Sometimes a phonetic process becomes **phonologized**, wherein the phonetic process becomes a phonological process.
    - Here are some examples from Hyman (2013) of processes that can either be phonetic or phonological, depending on the language.
    + If the triggering environment disappears due to a sound change, the phonetic conditioning is lost, and the process is unambigously phonological (maybe even resulting in contrast).

process |     subsequent developments | (incl. loss of trigger)
|---|---|---|
lengthening before voiced Cs: | /ab/ → [a:b] | (> a:p)
palatalization: |   /ki/ → [k^j i] |(> či, ši, tsi, si)
high vowel frication:  | /ku/ → [k^h u] |(> k^x u, k^f u, p^f u, fu)
anticipatory nasalization: | /an/  → [ãn] | (> ã^N, ã:, ã)
umlaut, metaphony:  | /aCi/  → [æCi] |(> εCi, εCә, εC)
tonogenesis from coda: |  /aʔ/ → [áʔ] | (> á) |
tonogenesis from phonation: | /a̰ʔ/ → [à̰ʔ] | (> à) |
tonal bifurcation from onset: | /bá/ → [bǎ] | (> pǎ) |
[Phonological and phonetic "doublets" from Hyman (2013)]

- How do we determine what's phonetic and what's phonological if it's like one of the processes above?
    + This isn't as easy as you might think…
    + Here are some characteristic differences from Hyman (2013), who cites: Cohn 1998, 2007; Keating 1996; Keyser and Stevens 2001; Kingston 2007; Pierrehumbert 1990; Stevens and Keyser 1989, etc.
    + Both phonology and phonetics seem to be language-specific to some degree.
    + Both phonology and phonetics seem to be subject to optionality to some degree.

| phonetics | phonology |
| --- | --- |
|gradient | categorical|
|continuous | discrete|
|quantitative | qualitative|
|physical | symbolic|
|analog | digital|
[Phonetics vs. phonology in Hyman (2013)]

- Two traditional diagnostics from Hyman (2013). A process has been phonologized if…
    + A phonetic effect is exaggerated beyond what can be considered universal (e.g. duration increases more than we'd expect)
    + A ‘categorical’ rule of phonology refers to it. (e.g. a clearly phonological process refers to vowel length, than that length must be phonological)

- Another view is that phonetics and phonology should not be treated in a simple feed-forward modular framework.
    + Instead, phonology can *refer directly* to phonetic characteristics, beyond just features. Both take very seriously the idea of functionally motivated constraints.
    + Two papers today:
        * Hayes (1999): A feedforward model, except for the induction of phonological constraints. Learning constraints involves a tradeoff between increasing ease of articulation and minimizing complexity.
        * Steriade (2001): Complicated typological patterns in assimilation can be explained by appealing to ease of perception and confusability.
        - Both papers use maps of difficulty: one for articulation (Hayes) andd one for perception (Steriade).

# Hayes (1999)
- Questions for discussion:
    + What are the main goals of the paper?
    + What factors influence the ease of voicing in obstruents?
        * Let's go over them and discuss how and why.
        * What about sonorants?
    - Where does the map of articulatory difficulty come from?
    - How is the map used to induce constraints?
    - Under Hayes' model, to what extent is CON universal?
    - Does Hayes' model address the too-many-repairs problem?
    - What constraints (if any) have we talked about that couldn't be induced under the algorithm presented here?
# Recap

