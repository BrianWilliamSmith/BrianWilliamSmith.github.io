<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
	<meta charset="utf-8"/>
	<title>Introduction and Review</title>
	<meta name="author" content="Brian W. Smith"/>
	<meta name="date" content="8/6/2019"/>
	<meta name="comment" content="For USC Ling 531A and Ling 401 Fall 2019"/>
</head>
<body>

<h1 id="introductionandreview">Introduction and Review</h1>

<div class="TOC">

<ul>
<li><a href="#introductionandreview">Introduction and Review</a>
<ul>
<li><a href="#courseoverview">Course overview</a></li>
<li><a href="#generativephonology">Generative phonology</a></li>
<li><a href="#productivity">Productivity</a></li>
<li><a href="#phonemesandallophones.">Phonemes and allophones.</a></li>
<li><a href="#alternationsandphonotactics">Alternations and phonotactics</a></li>
<li><a href="#distributionsandphonemicanalysis">Distributions and phonemic analysis</a></li>
<li><a href="#minimalpairsandnear-minimalpairs">Minimal pairs and near-minimal pairs</a></li>
<li><a href="#complementarydistribution">Complementary distribution</a></li>
<li><a href="#morepractice">More practice</a></li>
<li><a href="#limitationsoftheflowchart">Limitations of the flowchart</a></li>
<li><a href="#complementarydistributionrevisited">Complementary distribution, revisited</a></li>
<li><a href="#partiallypredictable:positionalneutralizationcontextually-limitedcontrast">Partially predictable: positional neutralization / contextually-limited contrast</a></li>
<li><a href="#minimalpairsrevisiteddisplacedcontrast">Minimal pairs, revisited (displaced contrast)</a></li>
<li><a href="#recap">Recap</a></li>
<li><a href="#goalsofphonologyandphonologicaldata">Goals of phonology and phonological data</a></li>
</ul>
</li>
</ul>
</div>

<h2 id="courseoverview">Course overview</h2>

<ul>
<li>This course is about phonological theories, especially evaluating, comparing, and applying them. We&#8217;re going to be focusing primarily on Optimality Theory, a framework that emerged in the early 1990s and replaced rules with constraints.</li>
<li>Plan

<ul>
<li>Syllabus, Slack, Google docs, and you.</li>
<li>This handout. Note: handouts will usually span multiple class meetings; this handout is exceptionally long and detailed.</li>
<li>Think of an answer to&#8230;

<ul>
<li>&#8220;What are other possible goals of phonological theory?&#8221;</li>
<li>&#8220;What are phonological data?&#8221;</li>
</ul></li>
</ul></li>
</ul>

<h2 id="generativephonology">Generative phonology</h2>

<ul>
<li>The central premise of Generative Grammar is that linguistic knowledge consists of both a <strong>grammar</strong> and a <strong>lexicon</strong>.</li>
<li>The lexicon contains all unpredictable information about words/morphemes, including their underlying representations (URs).

<ul>
<li>Working assumption #1: every morpheme has exactly one UR.</li>
<li>Working assumption #2: URs are built solely of sounds from a language&#8217;s phoneme inventory.</li>
</ul></li>
<li>The grammar is a process or algorithm that takes URs and derives Surface Representations (SRs). The grammar captures all predictable information.

<ul>
<li>Entailment of working assumption #1: if a morpheme has different SRs, differences between those SRs are derived via the grammar.</li>
</ul></li>
<li>The process of generating SRs from URs is a <strong>derivation</strong>.</li>
</ul>

<p>[Example of a derivation]
Lexicon | Grammar (simplified) | Surface forms
| - | - | - |
/bræg/+/d/ |make /d/ voiceless after a voiceless segment | [brægd]
/hæk/+/d/ |make /d/ voiceless after a voiceless segment | [hækt]
/su/+/d/ |make /d/ voiceless after a voiceless segment | [sud]</p>

<ul>
<li>The grammar and lexicon together result in a set UR-SR mappings, a.k.a. input-output mappings:

<ul>
<li>/bræg+d/ → [brægd]</li>
<li>/hæk+d/ → [hækt]</li>
<li>/su+d/ → [sud]</li>
<li>etc.</li>
</ul></li>
<li>No matter whether you have rules or constraints:

<ul>
<li>A generative grammar conceives of language as a process or algorithm that generates all possible SRs from a set of URs, which can be concatenated in various ways.</li>
<li>A generative grammar has three major design goals:

<ul>
<li>Be parsimonious: make the algorithm as simple and general as possible.</li>
<li>Don&#8217;t undergenerate: ensure that all of the possible forms of a language are possible outputs of the grammar.</li>
<li>Don&#8217;t overgenerate: ensure that none of the impossible forms are generated by mistake.</li>
</ul></li>
</ul></li>
</ul>

<h2 id="productivity">Productivity</h2>

<ul>
<li>An important feature: we can apply the grammar to novel words, just like kids and adults do.</li>
</ul>

<p>[Applying devoicing to novel words]
Lexicon | Grammar (simplified)| Surface forms
 &#8211; | &#8211; | &#8211;
/tiʧ/+/d/	|	make /d/ voiceless after a voiceless segment |	[tiʧt]
/go/+/d/	|	make /d/ voiceless after a voiceless segment 	|	[god]
/rɪk/+/d/	|	make /d/ voiceless after a voiceless segment 	|	[rɪkt]</p>

<ul>
<li>A grammatical process&#8217;s <strong>productivity</strong> in a particular language is a measure of…

<ul>
<li>The extent to which the process is applied to existing words.</li>
<li>The capacity of the process to apply in novel circumstances.</li>
</ul></li>
<li>The fact that speakers can apply processes to words they&#8217;ve never heard before, where memorization is impossible, supports the claim that speakers have internalized the grammatical processes of their language.

<ul>
<li>This argument is so important that Chomsky (1980) gave it a name: poverty of the stimulus.</li>
</ul></li>
</ul>

<figure>
<img src="Ricking.jpg" alt="Ricking from Berko Gleason's 1958 wug study" />
<figcaption>Ricking from Berko Gleason&#8217;s 1958 wug study</figcaption>
</figure>

<h2 id="phonemesandallophones.">Phonemes and allophones.</h2>

<ul>
<li>Every language has a limited set of <strong>phonemes</strong>. A phoneme is a label for a set of sounds that are basically the same (more on this below).</li>
<li>The variants of a phoneme are called <strong>allophones</strong>.</li>
<li>Allophonic variation is often structured and predictable based on phonological context.

<ul>
<li>English /l/

<ul>
<li>[l] in syllable onsets <em>(leaf)</em></li>
<li>[ɬ] in syllable codas <em>(feel)</em></li>
</ul></li>
<li>American English /t/

<ul>
<li>[tʰ] before V́ <em>(time)</em></li>
<li>[ʔt] in syllable codas <em>(cat)</em></li>
<li>[ɾ] between vowels <em>(city)</em></li>
<li>[ʧ] before [r] <em>(tree)</em></li>
<li>[t] elsewhere <em>(sty)</em></li>
</ul></li>
</ul></li>
<li>When there are multiple allophones of a phoneme, the form of the phoneme usually matches one of the allophones.

<ul>
<li> One of the forms is &#8220;basic.&#8221;</li>
<li> The other forms are derived via the grammar.</li>
</ul></li>
<li>Notation

<ul>
<li> Phonemes get slashes (e.g. /t/).</li>
<li> Allophones get square brackets (e.g. [t]).</li>
</ul></li>
<li>Contrast and predictability

<ul>
<li> Phonemes are contrastive and unpredictable.

<ul>
<li> Two sounds are contrastive/distinctive if the difference between them is meaningful: substitution of one for the other can lead to a new word.</li>
<li> Unpredictable: &#8220;I have a new English word that rhymes with winter, does it begin with a t or l?&#8221;</li>
</ul></li>
<li> Allophones are usually non-contrastive and predictable.
- Predictable: &#8220;I have a new English word that rhymes with winter, does it begin with [l] or [ɫ]?&#8221;

<ul>
<li>If the allophones are unpredictable, that&#8217;s <strong>free variation</strong>.</li>
</ul></li>
</ul></li>
<li>Phonemes and allophones are psychologically real to some degree.

<ul>
<li> Language users often &#8220;feel&#8221; that two sounds count the same.</li>
<li>Writing systems and transcriptions in introductory linguistics courses are usually phonemic.</li>
</ul></li>
<li>We assume that every UR in a language consists solely of the phonemes of that language.

<ul>
<li>This is why URs are also called phonemic representations.</li>
</ul></li>
</ul>

<h2 id="alternationsandphonotactics">Alternations and phonotactics</h2>

<ul>
<li>We talk about <strong>morphemes</strong> and <strong>allomorphs</strong> in a similar way.

<ul>
<li> When a morpheme has multiple surface variants (allomorphs), we call the pattern an <strong>alternation</strong>.</li>
<li> Terminology examples:
- &#8220;In English, the plural morpheme alternates between [z] and [s]&#8221;
- &#8220;In the English plural, [z] alternates with [s]&#8221;

<ul>
<li>&#8220;The English plural shows the alternation [z] ~ [s]&#8221;</li>
</ul></li>
</ul></li>
<li>Alternations are often contrasted with <strong>phonotactics</strong>, static restrictions on the distribution of sounds.

<ul>
<li>Examples:
- &#8220;English words cannot end in lax vowels, except [ə], [ɔ] and [ɑ]&#8221;

<ul>
<li>&#8220;Lax vowels in English cannot be immediately followed by a vowel&#8221;</li>
</ul></li>
<li> Some (but not all) phonotactics result in alternations.</li>
<li> Most (but not all) alternations are the result of phonotactics.</li>
</ul></li>
</ul>

<h2 id="distributionsandphonemicanalysis">Distributions and phonemic analysis</h2>

<ul>
<li><strong>Phonemic analysis</strong> is a method of phonological analysis that explores the contextual distribution of segments within a language.

<ul>
<li> Essentially, decide how to group the sounds into phonemes.</li>
<li> In the first half of the twentieth century, phonemic analysis was the goal of pre-generative Structuralists like Edward Sapir.
- The Structuralist view of phonemes and allophones differs from the one here: there were no underlying forms or generative grammars.

<ul>
<li> According to Structuralist phonemic analysis, there was always a perfectly predictable mapping between phonemes and allophones. This isn&#8217;t always obtainable.</li>
</ul></li>
</ul></li>
</ul>

<figure>
<img src="flowchart.png" alt="Flowchart reproduced from Language Files, </br> with some additions by me" />
<figcaption>Flowchart reproduced from Language Files, </br> with some additions by me</figcaption>
</figure>

<h2 id="minimalpairsandnear-minimalpairs">Minimal pairs and near-minimal pairs</h2>

<ul>
<li>A <strong>minimal pair</strong> is a pair of words that differ in meaning and exactly one sound.</li>
<li>Here are some English words with various vowels.

<ul>
<li>We can conclude some of these vowels belong to different phonemes.</li>
<li>Walk through the argument carefully. (What assumptions does it rely on?)</li>
</ul></li>
</ul>

<p>[Some English words]
| &#8212; | &#8212; | &#8212; | &#8212;|
|[ˈsut]	|&#8216;suit&#8217;	|[ˈpʌt]	|&#8216;putt&#8217;|
|[ˈʃɪn]	|&#8216;shin&#8217;	|[ˈʃɪp]	|&#8216;ship&#8217;|
|[ˈʃɪp]	|&#8216;ship&#8217;	|[ˈbut]	|&#8216;boot&#8217;|
|[ˈpʊt]	|&#8216;put&#8217;	|[ˈʃin]	|&#8216;sheen&#8217;|
|[ˈsʊt]	|&#8216;soot&#8217; |[ˈbʌt]	|&#8216;butt&#8217;|</p>

<ul>
<li>What if we can&#8217;t find minimal pairs for two sounds? (e.g. [ʃ] and [ʒ] in English)

<ul>
<li>Answer: <strong>near-minimal pairs</strong></li>
</ul></li>
</ul>

<h2 id="complementarydistribution">Complementary distribution</h2>

<ul>
<li>If two sounds occur in complementary environments (are in <strong>complementary distribution</strong>) then they may be allophones of the same phoneme.</li>
</ul>

<p>[English example of [n] and dental [n] from Bruce Hayes' Introductory Phonology textbook]
| &#8212; | &#8212; | &#8212; | &#8212; |
|[ˈnoʊ]	|&#8216;know&#8217;	|[ˈtɛn̪θ]	|&#8216;tenth&#8217;|
|[əˈnoɪ]|&#8216;annoy&#8217;|	[ˈmʌn̪θ]	|&#8216;month&#8217;|
|[ˈʌnjən]|&#8216;onion&#8217;|	[ˈpæn̪θɚ]|&#8216;panther&#8217;|
|[ˈnʌn]	|&#8216;nun&#8217;	|[krəˈsæn̪θəməm]	|&#8216;chrysanthemum&#8217;|</p>

<h2 id="morepractice">More practice</h2>

<ol>
<li>in English, are [l] and [d] allophones of the same phoneme, or realizations of different phonemes?</li>
<li>Propose a phonemic analysis for [l] and [d] in Setswana, also known as Tswana, a Niger-Congo language from Botswana with about 4.5 million speakers.</li>
</ol>

<p>[Setswana problem from Odden (2005)]
|&#8212;|&#8212;|&#8212;|&#8212;|
|[lefifi]	|&#8216;darkness&#8217;	|[loleme]	|&#8216;tongue&#8217;|
|[selɛpɛ]	|&#8216;axe&#8217;	|[molɔmo]	|&#8216;mouth&#8217;|
|[xobala]	|&#8216;to read&#8217;	|[mmadi]	|&#8216;reader&#8217;|
|[lerumɔ]	|&#8216;spear&#8217;	|[xoɲala]	|&#8216;to marry&#8217;|
|[loxadima]	|&#8216;lightning flash&#8217;	|[diʤɔ]	|&#8216;food&#8217;|
|[dumɛla]	|&#8216;greetings&#8217;	|[feedi]	|&#8216;sweeper&#8217;|
|[lokwalɔ]	|&#8216;letter&#8217;	|[kʰudu]	|&#8216;tortoise&#8217;|
|[mosadi]	|&#8216;woman&#8217;	|[podi]	|&#8216;goat&#8217;|
|[badisa]	|&#8216;the herd&#8217;	|[hudi]	|&#8216;wild duck&#8217;|</p>

<ul>
<li>Important point to remember: whether two sounds are different phonemes or allophones of the same phoneme depends on the language.</li>
<li>Another good example is how English and Spanish divide up the sounds [ɾ], [d], [ð]:

<ul>
<li>English [ɾ]~[d] vs. [ð]</li>
<li>Spanish [ɾ] vs. [d]~[ð]</li>
</ul></li>
</ul>

<h2 id="limitationsoftheflowchart">Limitations of the flowchart</h2>

<ul>
<li>Three places where flowchart thinking needs tweaking.

<ul>
<li>If two sounds are in complementary distribution they may be allophones of the same phoneme, but they aren&#8217;t necessarily so.</li>
<li><strong>Contextually-limited contrast</strong> is a case where different phonemes share an allophone. In that allophone&#8217;s environment, there&#8217;s no surface contrast between the phonemes. (see t/d above)</li>
<li>If there is a minimal pair, we can only conclude that there&#8217;s some difference between the Urs of the two words. It&#8217;s not necessarily the case that the differing sound is what&#8217;s contrastive.</li>
</ul></li>
<li>Based on these, together with free variation, it becomes clearer why a perfectly predictable mapping between phonemes and allophones is unobtainable.</li>
</ul>

<h2 id="complementarydistributionrevisited">Complementary distribution, revisited</h2>

<ul>
<li>Two sounds in complementary distribution may be allophones of the same phoneme.</li>
<li>In what environments do you find [l]? [ɫ̪]?</li>
</ul>

<p>[ [l] and dental [l] from Bruce Hayes' introductory phonology textbook ]
|&#8212;|&#8212;|&#8212;|&#8212;|
|[ˈlɪsən]	|&#8216;listen&#8217;	|[ˈwɛɫ̪θ]	|&#8216;wealth&#8217;
|[ˈluz]	|&#8216;lose&#8217;|	[ˈhɛɫ̪θ]	|&#8216;health&#8217;
|[əˈlaʊ]	|&#8216;allow&#8217;	|[ˈfɪɫ̪θi]|	&#8216;filthy&#8217;
|[əˈɡloʊ]	|&#8216;aglow&#8217;	|[ˈtɪɫ̪θ]|	&#8216;tilth&#8217;
|[ˈblɛnd]	|&#8216;blend&#8217;	|[ˈstɛɫ̪θ]|	&#8216;stealth&#8217;</p>

<ul>
<li>Are [n] and [ɫ̪] in complementary distribution? [l] and [n̪]?</li>
</ul>

<p>[ [n] and dental [n]]
| &#8212; | &#8212; | &#8212; | &#8212; |
|[ˈnoʊ]	|&#8216;know&#8217;	|[ˈtɛn̪θ]	|&#8216;tenth&#8217;|
|[əˈnoɪ]|&#8216;annoy&#8217;|	[ˈmʌn̪θ]	|&#8216;month&#8217;|
|[ˈʌnjən]|&#8216;onion&#8217;|	[ˈpæn̪θɚ]|&#8216;panther&#8217;|
|[ˈnʌn]	|&#8216;nun&#8217;	|[krəˈsæn̪θəməm]	|&#8216;chrysanthemum&#8217;|</p>

<ul>
<li>Also consider English [h] and [ŋ].</li>
<li>What does this mean for our algorithm of phonemic analysis?</li>
</ul>

<h2 id="partiallypredictable:positionalneutralizationcontextually-limitedcontrast">Partially predictable: positional neutralization / contextually-limited contrast</h2>

<ul>
<li><strong>Positional neutralization</strong> occurs when an underlying contrast between two phonemes disappears in a certain environment. In that position, the contrast is neutralized.</li>
<li>This is also called <strong>contextually-limited contrast</strong>, since the contrast is limited to a particular (non-neutralizing) context.</li>
</ul>

<p>[/t/, /d/ and tapping]
|&#8212; | &#8212; | &#8212; | &#8212; | &#8212; | &#8212; | &#8212; |
|[wɛt]|	&#8216;wet&#8217;|	[wɛɾɚ]|	&#8216;wetter&#8217;	|[wɛɾəst]|	&#8216;wettest&#8217;|	[wɛɾɪŋ]	|&#8216;wetting&#8217;|
|[bæt]|	&#8216;bat&#8217;|	[bæɾɚ]|	&#8216;batter&#8217;	| | |		[bæɾɪŋ]|	&#8216;batting&#8217;|
|[sæd]|	&#8216;sad&#8217;|	[sæɾɚ]|	&#8216;sadder&#8217;	|[sæɾəst]|	&#8216;saddest&#8217;		| | |
|[ʃut]|	&#8216;shoot&#8217;|	[ʃuɾɚ]|	&#8216;shooter&#8217;|		| |	[ʃuɾɪŋ]|	&#8216;shooting&#8217;|
|[fid]|	&#8216;feed&#8217;|	[fiɾɚ]|	&#8216;feeder&#8217;	|	| |	[fiɾɪŋ]|	&#8216;feeding&#8217;|
|[laʊd]|	&#8216;loud&#8217;|	[laʊɾɚ]|	&#8216;louder&#8217;|	[laʊɾəst]|	&#8216;loudest&#8217;| | |		
|[wɛd]|	&#8216;wed&#8217;|			| |		| |[wɛɾɪŋ]|	&#8216;wedding&#8217;|</p>

<ul>
<li>Another example: English nasals

<ul>
<li>/n/ optionally assimilates to the place of articulation of the following segment</li>
<li>The prefix <em>in-</em>

<ul>
<li>[n] inaccessible, intolerant	</li>
<li>[m] impossible</li>
<li>[ŋ] inconsolable</li>
</ul></li>
<li>The word <em>phone</em>

<ul>
<li>[n] phone, phone number 		</li>
<li>[m] phone book</li>
<li>[ŋ] phone cord</li>
</ul></li>
<li>Contrast: foam ≠ phone</li>
<li>Positional neutralization: foam book = phone book</li>
<li>But: /ŋ/ is always [ŋ].

<ul>
<li>[ŋ] not [n]: ringtone (≠ ri[n]tone)</li>
<li>[ŋ] not [m]: songbook (≠ so[m]book)</li>
</ul></li>
<li>A relatively complicated phonemicization.</li>
</ul></li>
</ul>

<h2 id="minimalpairsrevisiteddisplacedcontrast">Minimal pairs, revisited (displaced contrast)</h2>

<ul>
<li>Based on the data below, do [aɪ] and [ʌɪ] contrast in this dialect of English, or are they allophones of the same phoneme (if so, describe their distribution)?</li>
</ul>

<p>[ [aɪ] and [ʌɪ] in speakers from the Mid-Atlantic Region, New England, and Canada]
|&#8211;|&#8211;|
|[ˈlʌɪk]	|[ˈʤaɪb]	|[ˈklaɪm] | [ˈraɪð]
|[ˈflʌɪt]	|[ˈtɹʌɪp]	|[ˈʃaɪn]|[ˈwaɪd]
|[ˈsnʌɪp]	|[ˈlʌɪf]	|[ˈbaɪ]	|[əˈblaɪʤ]
|[ˈlaɪv]	|[ˈʌɪs]		|[ˈspaɪ]|[ˈsaɪd]	</p>

<ul>
<li>This process interacts with tapping.</li>
</ul>

<p>[Tapping and Canadian raising]
|&#8211;|&#8211;|&#8211;|
|[ˈrʌɪt]	|[ˈrʌɪɾɚ]	|&#8216;writer&#8217;
|[ˈraɪd]	|[ˈraɪɾɚ]	|&#8216;rider&#8217;
|[ˈslaɪd]	|[ˈslaɪɾɪŋ]	|&#8216;sliding&#8217;
|[ˈslʌɪt]	|[ˈslʌɪɾɪŋ]	|&#8216;slighting&#8217;</p>

<ul>
<li>Now looking at the second set of data, would you conclude that [aɪ] and [ʌɪ] are contrastive in this dialect?</li>
<li>[ˈɹʌɪɾɚ] and [ˈɹaɪɾɚ] are pronounced differently, because their underlying forms are different.

<ul>
<li>What is the contrast between their underlying forms?</li>
<li>In one sense, the underlying contrast has been neutralized, but in another sense, the underlying contrast can still be seen, because of its effects on another rule.</li>
<li>So, we can say that the underlying contrast between the phonemes /t/ and /d/ has been <strong>displaced</strong> onto the allophones [aɪ] and [ʌɪ] of the phoneme /aɪ/.</li>
</ul></li>
<li>What does this mean for our algorithm of phonemic analysis?

<ul>
<li>If two different words' surface forms are exactly the same except for one sound, we previously concluded that means those two sounds come from different phonemes.</li>
<li>But really, all we can conclude is that there is some difference between the underlying forms.</li>
<li>Moral: it&#8217;s safest to start by looking at monomorphemic words, since any minimal contrasts there probably come from exactly the sounds that differ.</li>
</ul></li>
</ul>

<h2 id="recap">Recap</h2>

<ul>
<li>Lexicon and grammar</li>
<li>Underlying forms, surface forms, mappings</li>
<li>Phonemes and allophones</li>
<li>Morphemes and allomorphs</li>
<li>Alternations and phonotactics</li>
<li>Phonemic analysis and distributions

<ul>
<li>Contrastive distribution

<ul>
<li>Minimal pairs and near-minimal pairs</li>
<li>Displaced contrast</li>
</ul></li>
<li>Complementary distribution</li>
<li>Contextually-limited contrast / positional neutralization</li>
<li>Free variation</li>
</ul></li>
<li>Ideas that go together

<ul>
<li>Minimal pairs - contrastive distribution - near-minimal pairs - unpredictable - contrastive - separate phonemes</li>
<li>Complementary distribution - predictable - non-contrastive - allophones of one phoneme</li>
<li>Free variation - allophones of one phoneme but unpredictable and non-contrastive</li>
<li>Overlapping distribution - can be free variation or contrastive distribution</li>
<li>Contextually limited contrast / positional neutralization - partially predictable - partially contrastive - an allophone is shared by two phonemes</li>
</ul></li>
</ul>

<h2 id="goalsofphonologyandphonologicaldata">Goals of phonology and phonological data</h2>

<ul>
<li>Repeated from above:

<ul>
<li>A generative grammar conceives of language as a process or algorithm that generates all possible SRs from a set of URs, which can be concatenated in various ways.</li>
<li>A generative grammar has three major design goals:

<ul>
<li>Be parsimonious: make the algorithm as simple and general as possible.</li>
<li>Don&#8217;t undergenerate: ensure that all of the possible forms of a language are possible outputs of the grammar.</li>
<li>Don&#8217;t overgenerate: ensure that none of the impossible forms are generated by mistake.</li>
</ul></li>
</ul></li>
<li>What are other possible goals?</li>
<li>Phonologists rarely disagree about the goals, but often disagree on the specifics:

<ul>
<li>How do we decide what&#8217;s possible/impossible in a language? This is especially relevant for exceptions and gaps.</li>
<li>What counts as data? What about judgments? Corpus data? Language games?</li>
<li>What does it mean for an algorithm to be simple or general? Is it fewer symbols? Shorter running time? Better performance on new data?</li>
<li>Which design goal(s) should be prioritized?</li>
<li>Should the algorithm be abstract or grounded in human cognition?</li>
<li>Relatedly: do we want the grammar to model knowledge of what&#8217;s grammatical (linguistic competence) or mimic actual human performance?</li>
<li>A clear example of the last question: do we want our model to generate humanlike speech errors?</li>
</ul></li>
</ul>

</body>
</html>

